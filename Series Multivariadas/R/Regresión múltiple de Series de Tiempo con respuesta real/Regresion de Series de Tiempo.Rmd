---
title: "Regresion de Series de Tiempo"
output: github_document
#output: html_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Nota: Para realizar gráficos con objetos tsibble consulte https://www.r-bloggers.com/2020/10/how-to-visualize-time-series-data-tidy-forecasting-in-r/

# Regresión Lineal Simple Con errores no-autocorrelacionados.

Vamos a tratar de relacionar los cambios porcentuales trimestrales del gasto real del consumo personal$(y)$ y el ingreso disponible real persona. Primero visualizamos las series, las cuales son al menos estables en media.

```{r datos reg1}
library(feasts)
library(fpp3)
data(us_change) ##Del paquete fpp3
str(us_change)
us_change %>%
  pivot_longer(c(Consumption, Income), names_to="Series") %>%
  autoplot(value) +
  labs(y = "% change")
```
También se puede usar el paquete timetk
```{r timetk}
library(timetk)
library(tidyquant)
library(stringr)
?timetk::plot_time_series()
Ts_multiple=us_change%>%pivot_longer(c(Consumption,Income,Production,Savings,Unemployment))
Ts_multiple$Quarter=as.Date(Ts_multiple$Quarter)
Ts_multiple%>%group_by(name)%>%timetk::plot_time_series(Quarter ,value,.facet_ncol  = 2,.interactive  = FALSE)

```


Llevemos a cabo ahora unas gráficas exploratorias.

```{r exploratoria reg1}
us_change %>%
  ggplot(aes(x = Income, y = Consumption)) +
  labs(y = "Consumption (quarterly % change)",
       x = "Income (quarterly % change)") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

```

El anterior diagrama de dispersión no permite ver una relación lineal muy clara de forma instantánea.
Exploremos las autocorrelaciones.

```{r reg 1 autocorrelaciones}
us_change %>% ACF(Income,lag_max = 20) %>% 
  autoplot()

us_change %>% ACF(Consumption,lag_max = 20) %>% 
  autoplot()

us_change %>% CCF(Consumption,Income,lag_max = 20) %>% 
  autoplot()
```

Serán independientes las series??Usar el pre-blanqueamineto de las series(Tarea)

También usemos timetk para explorar las autocorrelaciones simples y parciales

```{r timetk correlaciones}
Ts_multiple%>%group_by(name)%>%plot_acf_diagnostics(Quarter ,value,.lags=30,.interactive=FALSE)
us_change%>%plot_acf_diagnostics(.date_var=Quater,.value=Consumption,.ccf_vars = c(Income,Production,Savings,Unemployment),.lags=15,.interactive=FALSE,.facet_ncol  = 2,.show_ccf_vars_only=TRUE)
```

Parece tener sentido que hagamos una regresión lineal simple para mirar la existencia de una relación contemporánea(es decir instantánea).

Ahora veamos el ajuste del modelo.

```{r ajuste reg1}
Ajustesreg1=us_change %>%
  model(TSLM(Consumption ~ Income)) %>%
  report()
```

Note que el poder explicativo del ingreso no es muy alto.

```{r gls}
salida_sincorrelacion=nlme::gls(Consumption ~ Income,us_change)
corr = nlme::corARMA(value=c(0.2,0.4),p = 1, q = 1)
corr=nlme::Initialize(corr,us_change)
nlme::corMatrix(corr)
dim(nlme::corMatrix(corr))
salida_concorrelacion=nlme::gls(Consumption ~ Income,us_change,correlation = corr)
summary(salida_concorrelacion)
library(lmtest)
coeftest(salida_concorrelacion)
```


## Verficación de los supuestos

```{r supuestos reg1}
Ajustesreg1%>% gg_tsresiduals()

```

La gráfica de los residuales no parece mostrar patrones sistemáticos(tendencia o ciclos), sin embargo si parecen estar autocorrelacionados. También parecen tener unos valores atípicos. Con esto, nos podemos dar cuenta que el ajuste del modelo no es bueno, lo cual implica que es necesario cambiar el modelo. Vamos ahora a considerar ahora un modelo donde se incluyan mas variables, también se puede considerar que tenga en cuenta la estructura de autocorrelación presente en los residuales.

## Regresión múltiple
Vamos ahora a considerar que los cambios porcentuales del consumo no solo es función de los cambios porcentuales ingreso sino también de otras variable como producción, desempleo y ahorros. Vamos primero a graficar las series de tiempo de  las otras tres variables.

```{r timeplots Reg mult}
us_change %>%
  select(-Consumption, -Income) %>%
  pivot_longer(-Quarter) %>%
  ggplot(aes(Quarter, value, color = name)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  guides(colour = "none") +
  labs(y="% change")
```
```{r timeplots Reg mult todas}
us_change %>%
 pivot_longer(c(Consumption,Income,Production,Savings,Unemployment)) %>%
  ggplot(aes(Quarter, value, color = name)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  guides(colour = "none") +
  labs(y="% change")
```

Veamos ahora las descriptivas.

```{r descriptiva reg mul}
ts_todas=as.data.frame(us_change)
ts_todas_final=ts_todas[2:6]
acf(ts_todas_final,lag.max = 20)
```
Al chequear las correlaciones cruzadas del consumo con las otras variables vemos que parecer haber una relación temporal contemporánea.Recuerden que para que en efecto podamos estudiar bien las dependecias, hay que hacer un pre-blanqueo de almenos uno de las series, la cual en este caso la que parecer ser mas óptima es la serie de consumo que es la dependiente. Tarea(Hacer el pre-blanqueamiento de la serie consumo y chequear las autocorrelaciones cruzadas.)

```{r ccm reg mul}
x11()
MTS::ccm(ts_todas_final,lags=20)

```

```{r Diagrama de dispersión}
us_change %>%
  pivot_longer(Income:Unemployment,
               names_to = "regressor", values_to = "x") %>%
  ggplot(aes(x = x, y = Consumption)) +
  geom_point() +
  facet_wrap(. ~ regressor, scales = "free_x") +
  labs(y = "Consumption", x = "")
```


Con lo anteriormente mencionado podemos ver que hay una relación instantánea entre las variables explicativas y el consumo. Ahora corramos la regresión

```{r regresion mult Consumption}
fit_consMR <- us_change %>%
  model(tslm = TSLM(Consumption ~ Income + Production +
                                    Unemployment + Savings))
report(fit_consMR)
```

## Comparación de valores reales con los valores predichos

```{r comparacion predicho vs reales}
augment(fit_consMR) %>%
  ggplot(aes(x = Quarter)) +
  geom_line(aes(y = Consumption, colour = "Datos")) +
  geom_line(aes(y = .fitted, colour = "Ajustados")) +
  labs(y = NULL,
    title = "Porcentaje de Cambio en el consumo de US "
  ) +
  scale_colour_manual(values=c(Datos="black",Ajustados="#D55E00")) +
  guides(colour = guide_legend(title = NULL))

augment(fit_consMR) %>%
  ggplot(aes(x = Consumption, y = .fitted)) +
  geom_point() +
  labs(
    y = "Ajustados (Valores Predichos)",
    x = "Datos (Valores Reales)",
    title = "Porcentaje de Cambio en el consumo de US"
  ) +
  geom_abline(intercept = 0, slope = 1)

```



Para la evaluación del modelo, hay que chequear los supuestos básico de la regresión múltiple. 

```{r análisis de residuales}
library(tseries)
fit_consMR %>% gg_tsresiduals()

augment(fit_consMR) %>%
  features(.innov, ljung_box, lag = 10, dof = 5)

tseries::jarque.bera.test(augment(fit_consMR)$.innov)


```

## Relaciones Espurias

Cuando las series no son estacionarias(presentan tendencias), como sucede en muchas series de tiempo, el impacto pueden ser muy grande cuando se desea llevar a cabo la regresión. Puede suceder que aunque dos series de tiempo sean independientes pero no estacionarias, al llevar a cabo una regresión entre ellas, la regresión(lineal) nos muestre que si hay dependencia entre ellas. Eso lo conocemos como relaciones espurias. En el script de R vemos un ejemplo de simulación y un conjunto de datos reales. Mas adelante vemos como trabajar en este tipo de escenarios.

```{r simul espurias}
set.seed(123)
Xtind=arima.sim(n=500,list(order = c(0,1,0)))
set.seed(456)
Ytind=arima.sim(n=500,list(order = c(0,1,0)))
daily_index_simul <- as.Date(seq.Date(from = as.Date("2008-01-01"), # Starting date
                           length.out=500,
                           by = "day") )# Defining the time intervals to =       as.Date("2012-12-16"), # Ending date
df_simul=data.frame(Xtind=Xtind[2:501],Ytind=Ytind[2:501],daily_index_simul)
tibble_df_simul=tibble(df_simul)
ts_tibble_simul=as_tsibble(df_simul,index=daily_index_simul)
ts_tibble_simul_mult=ts_tibble_simul%>%pivot_longer(c(Xtind,Ytind),names_to = "serie",values_to = "valores")
ts_tibble_simul_mult%>%group_by(serie)%>%timetk::plot_time_series(daily_index_simul ,valores,.interactive  = FALSE)
```
Se lleva acabo las gráficas ACF, PACF, CCF y la regresión:

```{r regresion espurias no-estacionarias e independientes}
ts_tibble_simul %>% ACF(Ytind,lag_max = 20) %>% 
  autoplot()

ts_tibble_simul %>% ACF(Xtind,lag_max = 20) %>% 
  autoplot()

ts_tibble_simul %>% CCF(Ytind,Xtind,lag_max = 20) %>% 
  autoplot()

Ajustesreg1_espurias=ts_tibble_simul %>%
  model(TSLM(Ytind ~ Xtind)) %>%
  report()
```
Primero vale la pena señalar la fuerte autocorrelación cruzada entre las dos serie.Note ahora que los parámetros son altamente significativos, a pesar de que las series son independientes. Note que se propone la regresión:
$$y_t=\beta_0+\beta_1 x_t+\epsilon_t$$
donde $\{\epsilon_t\}$ es un proceso no autocorrelacionado en principio. Lo cual es equivalente a decir que
$$y_t-\beta_0-\beta_1 x_t=\epsilon_t,$$
es decir que existe una combinación lineal(\textit{de procesos no estacionarios que en este caso están integrados}) de $y_t$ y $x_t$ tal que es estacionaria, que es la definición de que los procesos están cointegrados o que hay una relación de cointegración entre esos procesos. Es decir, tiene sentido proponer una regresión lineal entre dos procesos no estacionarios, siempre que haya una relación de cointegración.

## Ejemplo Real Relaciones Espurias
Vamos a observar las series número de pasajeros anual en Australia y la producción anual de arroz en Guinea. En principio estas dos series no debería tener ninguna relación desde el punto de vista teórico y práctico. Ambas Series como veremos son no estacionarias y presentan tendencias.

```{r Espurias datos reales}
data("aus_airpassengers")
data("guinea_rice")
aus_airpassengers%>%timetk::plot_time_series(.value=Passengers,.date_var=Year,.smooth = FALSE)
guinea_rice%>%timetk::plot_time_series(.value=Production,.date_var=Year,.smooth = F)

```

```{r Espurias dispersión}
aus_airpassengers%>%left_join(guinea_rice,by="Year")%>%filter(Year<=2011) %>%ggplot(aes(x = Passengers, y = Production)) +
  geom_point() +
  labs(
    y = "Número de Pasajeros Aus(Millones)",
    x = "Producción de Arroz Guinea (Millones de Tons)",
    title = "Diagrama de Dispersión"
  ) 


ajuste_espurias=aus_airpassengers%>%left_join(guinea_rice,by="Year")%>%filter(Year<=2011) %>%model(fable::TSLM(Passengers~Production))
report(ajuste_espurias)

ajuste_espurias%>%feasts::gg_tsresiduals(type="innovation")
```
Note que el $R^2$ del ajuste es muy alto, pero también muestra una alta autocorrelación los residuales, lo cual un síntoma de relaciones espurias.

## Predictores útiles

```{r Intervencion}
library(readxl)
library(zoo)

Desempleo<- read_excel("Desempleo.xlsx", col_types = c("text", "numeric"), col_names=c('Fecha','TasaDesempleo'),skip=1)

Desempleo$Fecha=yearmonth(Desempleo$Fecha)
str(Desempleo)
ts_Desempleo=as_tsibble(Desempleo)
ts_Desempleo%>%timetk::plot_time_series(.value=TasaDesempleo,.date_var=Fecha,.smooth = F)

```

Note que debido al Covid, la tasa de desempleo creció durante el mes de Abril 2020, y se mantuvo por varios meses mas, sin embargo podemos notar que después de cierto periodo de tiempo, estamos regresando a los niveles que tenía la serie ante la pandemia. Esta intervención puede modelarse a través de variables dummy.Por ejemplo, si ajustamos un ARIMA automático a la serie y luego vemos si hay outliers, lo cuales se pueden modelar a través de intervenciones.

```{r Intervencion1}
library(tsoutliers)
ajuste_desempleo=ts_Desempleo%>%model(ARIMA(TasaDesempleo))
report(ajuste_desempleo)
ajuste_desempleo%>%coef()
autoarima_desempleo=forecast::auto.arima(ts_Desempleo)
resi= residuals(autoarima_desempleo)
coef= coefs2poly(autoarima_desempleo)
coef
outliers= tsoutliers::locate.outliers(resi,coef)
outliers
xreg = outliers.effects(outliers, length(resi))
xreg
```

##Dummy Estacionales

Vamos a crear Dummy Estacionales para modelar la Estacionalidad con base en la serie de producción de cerveza trimestral en Australia. Note que claramente hay un ciclo anual en esta serie trimestral.

```{r Dummy Estacionales}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
recent_production %>%
  autoplot(Beer) +
  labs(y = "Megalitros",
       title = "producción de cerveza trimestral en Australia")

```
###Mas exploración  del ciclo estacional

```{r exploracion estacionalidad}
aus_production %>% gg_season(Beer)
aus_production %>% gg_subseries(Beer)
aus_production %>% filter(year(Quarter) > 1991) %>% gg_lag(Beer)
aus_production %>% ACF(Beer) %>% autoplot()
```
## Exploración usando timetk
```{r}
require(timetk)
Prod_beer<-as_tibble(aus_production%>%select(Beer))
Prod_beer$Quarter<-as.Date(Prod_beer$Quarter)
Prod_beer%>%plot_seasonal_diagnostics(Quarter,Beer,.feature_set = c("quarter","year"))
```


Vamos a ajustarle a esta serie un modelo con tendencia lineal y con dummy estacionales.La función season() reconoce inmediatamente que para una serie trimestral, el ciclo tiene un periodo de 4, mientras que trend() reconoce que un una tendencia lineal. El modelo a ajustarse es el siguiente:

$$y_t=\beta_0+\beta_1 t+\beta_2 d_{2,t}+\beta_3 d_{3,t}+\beta_4 d_{4,t}+\epsilon_t$$
La variable del primer trimestre fue omitida, tal que los coeficientes asociados con los otros trimestres son medidos de la diferencia  entre esos trimestres y el primer trimestre.
```{r Dummy estacionales 1}
fit_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + season()))
report(fit_beer)

```
 Los resultados se interpretan de la siguiente manera:
 Hay una tendencia media a la baja de -0,34 megalitros por trimestre. En promedio, el segundo trimestre tiene una producción de 34,7 megalitros menos que el primer trimestre, el tercer trimestre tiene una producción de 17,8 megalitros menos que el primer trimestre y el cuarto trimestre tiene una producción de 72,8 megalitros más que el primer trimestre.
 
 Vamos ahora a ver el ajuste del modelo intramuestra:
 
```{r dummy estacionales 2}
augment(fit_beer) %>%
  ggplot(aes(x = Quarter)) +
  geom_line(aes(y = Beer, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  scale_colour_manual(
    values = c(Data = "black", Fitted = "#D55E00")
  ) +
  labs(y = "Megalitros",
       title = "producción de cerveza trimestral en Australia") +
  guides(colour = guide_legend(title = "Series"))
```
Note que se puede producir las variables Dummy como sigue:
```{r Dummy estacionales 3}
require(uroot)
require(forecast)
month1 <- seasonaldummy(ldeaths)
month1


seasonal.dummies(ldeaths)
```

 
## Componentes de Fourier
Vamos a hacer un ajuste haciendo una regresión con componentes de Fourier donde solo tomamos dos componentes en la suma. En este caso solo hay tres componentes de Fourier ya que el segundo componente del seno siempre va a dar cero.
```{r Fourier}
fourier_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + fourier(K = 2)))
report(fourier_beer)
```

## Pronóstico con Regresión

Vamos a ver como producir los pronósticos basados en el modelo de regresión lineal, y así mismo como producir los intervalos de pronóstico.

Vamos a utilizar las variables determinísticas para producir los pronósticos, en especial las variables dummy.El ejemplo que vamos a considerar que se desea predecir la producción trimestral de cerveza, la cual presenta una leve tendencia y una componente estacional, las cuales son modeladas por componentes determinísticas como se vió anteriormente. Para este caso los pronósticos ex-ante y ex-post resultan ser iguales.

```{r pronostico dummy}
 recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
recent_production %>%
  autoplot(Beer) +
  labs(y = "Megalitros",
       title = "producción de cerveza trimestral en Australia")
tail(recent_production)

fit_beer <- recent_production %>%
model(TSLM(Beer ~ trend() + season()))
fc_beer<-fabletools::forecast(fit_beer,h=8)

fc_beer%>%
  autoplot(recent_production)+
  labs(title="Pronóstico de la producción de cerveza usando Regresión para 2 años",
y="Megalitros")
```

Note que no hay que crear los valores futuros de las variables determinísticas, la función misma lo crea.

Tarea: Hacer los mismo usando las variables de Fourier.

# Pronóstico basado en una variable predictora 

Supongamos que se desea predecir el consumo con base en en el ingreso. Adicionalmente vamos a hacer escenarios de
predicción cuando suponemos que hay un incremento en el ingreso por encima del promedio histórico de $\bar{x}=0.73\%$ apróximadamente, y cuando tenemos un valor de incremento extremo del $12\%$.
```{r pronostico una variable predictora y escenarios}
fit_cons <- us_change %>%
  model(TSLM(Consumption ~ Income))
new_cons <- scenarios(
  "Incremento Promedio" = new_data(us_change, 4) %>%
    mutate(Income = mean(us_change$Income)),
  "Incremento Extremo" = new_data(us_change, 4) %>%
    mutate(Income = 12),
  names_to = "Escenario"
)
new_cons

fcast <- forecast(fit_cons, new_cons)

us_change %>%
  autoplot(Consumption) +
  autolayer(fcast) +
  labs(title = "Consumo Us", y = "% cambio")
fcast
```


## Pronóstico basados en multiples variables predictoras  y escenarios

Por ejemplo, se está interesado en comparar el cambio predicho en el consumo cuando hay un crecimiento constante de $1\%$ y $0.5\%$ respectivamente para el ingreso y los ahorros, sin cambios en la tasa de desempleo, versus una caída respectiva de $1\%$ y $0.5\%$, para cada uno de los trimestres luego del final del periodo de la muestra.  Note que los intervalos de predicción calculados no tienen en cuenta la incertidumbre  asociada a los valores futuros de las variables predictoras.

```{r Pronostico basados en escenarios}
fit_consBest <- us_change %>%
  model(
    lm = TSLM(Consumption ~ Income + Savings + Unemployment)
  )

future_scenarios <- scenarios(
  Increase = new_data(us_change, 4) %>%
    mutate(Income=1, Savings=0.5, Unemployment=0),
  Decrease = new_data(us_change, 4) %>%
    mutate(Income=-1, Savings=-0.5, Unemployment=0),
  names_to = "Scenario")

future_scenarios

fc <- forecast(fit_consBest, new_data = future_scenarios)
us_change %>%
  autoplot(Consumption) +
  autolayer(fc) +
  labs(title = "Consumo US", y = "% change")

fc
```

Tarea:Hacer los mismo pero incluir incrementos de 0.25 en cada periodo, y además el desempleo del escenario de incremento empieza en 0.25. Realizar lo mismo pero para el escenario de decrecimiento pero valores negativos y el decrecimiento es de -0.25.

Leer sección 7.8 libro fpp3.

### Modelos de Regresión Dinámica

Vamos a considerar que los errores del modelo de regresión son $\{\eta_t\}$ tal que
  

 $$y_{t}=\beta_0+\beta_1 x_{1,t}+\cdots,+\beta_k x_{k,t}+\eta_t$$
 y que asumimos que el modelo de los errores es un $arima(p,d,q)$
 $$\phi(B)(1-B)^d\eta_t=\theta(B)\epsilon_t$$

donde $\{\epsilon_t\}\sim RB(0,\sigma^2)$, es decir, el modelo tiene dos errores, los errores de la regresión $\eta_t$, y el error del modelo $arima$ que es $\epsilon_t$ que es un ruido blanco.

Vamos a usar la función ARIMA de el paquete \textit{fable}.Supongamos que la función es usada de la siguiente manera:

$ARIMA(y~ x +pdq(1,1,1))$, lo cual ajustará un modelo
$$y_t'=\beta_1x_t'+\eta_t'$$
donde $y_t'=y_t-y_{t-1}$, $x_t'=x_t-x_{t-1}$ y $\eta_t'=\eta_t-\eta_{t-1}$ con $\eta_t'=\phi_1+\eta_{t-1}'+\epsilon_t$, el cual es equivalente al modelo
$$y_t=\beta_0+\beta_1x_t+\eta_t$$
donde $\{\eta_t\}\sim ARIMA(1,1,0)$. Es decir, si $d=1$ en el argumento, todos las series son diferenciadas.

## Ejemplo Consumo depende del ingreso

Vamos a suponer que los cambios consumo dependen de los cambios en el ingreso y que vamos a tener en cuenta la estructura de autocorrelación en los residuales, a diferencia del primer ejemplo de este script.

Vamos a considerar primero el modelo automático sugerido por la función $ARIMA$ para los errores. Veamos primero las dos serie a relacionar.

```{r regresión dinámica 1}
us_change %>%
  pivot_longer(c(Consumption, Income),
               names_to = "var", values_to = "value") %>%
  ggplot(aes(x = Quarter, y = value)) +
  geom_line() +
  facet_grid(vars(var), scales = "free_y") +
  labs(title = "US consumption and personal income",
       y = "Quarterly % change")

```

Ahora veamos el ajuste con una propuesta automática para el modelo de los errores.
```{r Regresión dinámica 2}

fit <- us_change %>%
  fabletools::model(fable::ARIMA(Consumption ~ Income))
report(fit)
coef(fit)
```

Note que las series están en diferencias y no en niveles, por lo cual el procedimiento no sugiere una diferencia.Además todos los parámetros resultan significativos.

Nota: Recuerde construir el modelo para los errores usando las herramientas del análisis univariado de series de tiempo.

Así el modelo queda expresando de la siguiente manera:
$$y_t=0.5949310+0.1976247x_t+\eta_t$$ 

donde
$$\eta_t-0.7070037\eta_{t-1}=\epsilon_t-0.6172115\epsilon_{t-1}+0.2066358\epsilon_{t-2}$$

tal que

$$\{\epsilon_t\}\sim NID(0,0.3113)$$


Ahora obtengamos los dos conjuntos de residuales del modelo propuesto y chequeemos como se comportan:

```{r regresion dinámica 3}
bind_rows(
    `Residuales de la Regresion` =
        as_tibble(residuals(fit, type = "regression")),
    `Residuals ARIMA` =
        as_tibble(residuals(fit, type = "innovation")),
    .id = "type"
  ) %>%
  mutate(
    type = factor(type, levels=c(
      "Residuales de la Regresion", "Residuals ARIMA"))
  ) %>%
  ggplot(aes(x = Quarter, y = .resid)) +
  geom_line() +
  facet_grid(vars(type))
```

Por supuesto los residuales del modelo ARIMA 
$\{\hat{\epsilon}_t\}$ deberían parecerse a un ruido blanco.

## Chequeo de los Residuales del modelo

Veamos los residuales del modelo, es decir los residuales del modelo ARIMA.

```{r Regresión dinámica 4}
fit%>% feasts::gg_tsresiduals()

```

Qué podemos decir estos residuales comparados con el primer modelo que se ajustó?

Puede que queden outliers!!!

## Pronóstico   
Vamos a obtener el pronóstico del cambio porcentual del consumo para los siguientes 8 periodos o trimestres. Para esto, se asumirá que el cambio porcentual del ingreso será igual al porcentaje promedio de los últimos 40 años. Primero se crean los valores futuros, y luego se hace el pronóstico basados en el modelo ajustado.

```{r regresion dinámica pronostico}
us_change_future <- tsibble::new_data(us_change, 8) %>%
  dplyr::mutate(Income = mean(us_change$Income))
forecast(fit, new_data = us_change_future) %>%
  autoplot(us_change) +
  labs(y = "Cambio Porcentual")
```
Los intervalos de predicción para este modelo son más angostos que si hubiéramos ajustado un modelo ARIMA sin covariables, porque ahora podemos explicar parte de la variación en los datos utilizando el predictor de ingresos.

Es importante darse cuenta de que los intervalos de predicción de los modelos de regresión (con o sin errores ARIMA) no tienen en cuenta la incertidumbre en los pronósticos de los predictores. Por lo tanto, deben interpretarse como condicionales a los valores futuros supuestos (o estimados) de las variables predictoras.


## Ejemplo del pronóstico de la demanda de electricidad
Vamos a tratar de predecir la demanda de electricidad en Australia como función de la temperatura. Veamos la gráfica de las dos series:

```{r Electricidad 1}
##usando ffp3
data("vic_elec")
str(vic_elec)
head(vic_elec)
tail(vic_elec)
vic_elec %>%
  pivot_longer(c(Demand, Temperature), names_to="Series") %>%
  autoplot(value) +
  labs(y = "% change")
###Usando ggplot
vic_elec %>%
  pivot_longer(c(Demand, Temperature), names_to="Series") %>%
  ggplot(aes(x = Date, y = value, group = Series)) + 
  geom_line() + 
  facet_grid(vars(Series), scales = "free_y")   

###Usando timetk
vic_elec %>%
  pivot_longer(c(Demand, Temperature), names_to="Series") %>% 
    plot_time_series(
        .date_var = Date,
        .value = value,
        .facet_vars = c(Series), # Agrupar por estas
        .color_var = Series, 
        .interactive = FALSE,
        .legend_show = FALSE
    )



```
En la gráfica de las series de tiempo para todos los años se puede observar una relación interesante.

Evaluemos ahora como es la dependencia entre la temperatura y la demanda de energía. Se tiene la idea que se consume más electricidad en los días fríos debido a la calefacción y en los días calurosos debido al aire acondicionado. Veamos una gráfica entre la demanda diaria contra la temperatura máxima diaria, recordemos que las mediciones son cada media hora.

```{r electricidad2}
vic_elec_daily <- vic_elec %>%
  #filter(year(Time) == 2014) %>%  ###se activa si desea filtrar por año
  index_by(Date = date(Time)) %>%
  summarise(
    Demand = sum(Demand) / 1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)
  ) %>%
  mutate(Day_Type = case_when(
    Holiday ~ "Holiday",
    wday(Date) %in% 2:6 ~ "Weekday",
    TRUE ~ "Weekend"
  ))

vic_elec_daily %>%
  ggplot(aes(x = Temperature, y = Demand, colour = Day_Type)) +
  geom_point() +
  labs(y = "Demanda de electricidad (GW)",
       x = "Temperatura máxima diaria")
```

Note que parece haber una relación entre la demanda y la temperatura máxima diaria de forma no lineal y tiene forma de $U$. Además de eso también se observa la relación de los días entre semana, fin de semana y festivos. Veamos ahora la relación entre las variables, pero sólo para el año 2014.
```{r electricidad 3}
vic_elec_daily2014<- vic_elec %>%
  filter(year(Time) == 2014) %>%  ###se activa si desea filtrar por año
  index_by(Date = date(Time)) %>%
  summarise(
    Demand = sum(Demand) / 1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)
  ) %>%
  mutate(Day_Type = case_when(
    Holiday ~ "Holiday",
    wday(Date) %in% 2:6 ~ "Weekday",
    TRUE ~ "Weekend"
  ))


vic_elec_daily2014 %>%
  pivot_longer(c(Demand, Temperature)) %>%
  ggplot(aes(x = Date, y = value)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") + ylab("")
```
Vamos ahora a ajustar una regresión cuadrática entre las dos variables con errores \textit{ARMA}, adicionalmente se incluye una variable indicadora para saber especifica si el día es festivo o un día laboral. El modelo ARMA ajustado se hace forma automática, lo cual no es lo mas recomendable.

```{r electricidad 4}
fit <- vic_elec_daily2014 %>%
  model(ARIMA(Demand ~ Temperature + I(Temperature^2) +
                (Day_Type == "Weekday")))
fit %>% gg_tsresiduals()

report(fit)
coef(fit)

library(tseries)
augment(fit)%>% features(.innov,ljung_box,dof=9,lag=50)
tseries::jarque.bera.test(augment(fit)%>%pull(.innov))

```

Note que hay algunos parámetros que son no son significativos, adicionalmente se sugiere diferenciar las series, y también incluye una componente cíclica. La cual debería ser explorada con anticipación. El modelo debería ser refinado. Note también que el ajuste no es del todo idóneo, porque aún se mantiene una estructura de autocorrelación, además los residuales del modelo no parecen tener distribución normal y mantener colas pesadas, finalmente uno puede ver que parece haber una especie de heterocecasticidad en especial porque hay una varianza mayor al inicio y al final de los residuales, comparado con los meses de abril y mayo. Esto puede afectar los intervalos de predicción pero no la estimación puntual.(Cómo se puede mejorar?Tarea)

Vamos ahora a obtener el pronósticos del modelo basados en escenario estableciendo que la temperatura de los próximos 14 es de 16 grados. Por supuesto que lo ideal sería considerar los valores futuros de la variable predictora.

```{r electricidad 5}
vic_elec_future <- new_data(vic_elec_daily2014, 14) %>%
  mutate(
    Temperature = 26,
    Holiday = c(TRUE, rep(FALSE, 13)),
    Day_Type = case_when(
      Holiday ~ "Holiday",
      wday(Date) %in% 2:6 ~ "Weekday",
      TRUE ~ "Weekend"
    )
  )
forecast(fit, vic_elec_future) %>%
  autoplot(vic_elec_daily2014) +
  labs(title="Demanda de electricidad diaria: Estado Victoria",
       y="GW")
```

Como tarea es necesrio desarrollar las secciones 10.4 y 10.5 del libro fpp3.


## Predictores retardados

Veamos el siguiente ejemplo del libro fpp3. Una compañía de seguros de EE. UU. se anuncia en la televisión nacional en un intento de aumentar la cantidad de cotizaciones de seguros proporcionadas (y, en consecuencia, la cantidad de pólizas nuevas). Veamos la gráfica de las series el número de cotizaciones y el gasto en publicidad televisiva de la empresa cada mes desde enero de 2002 hasta abril de 2005.

```{r Predictores retardados 1}
data(insurance)##del paquete fpp3
insurance %>%
  pivot_longer(Quotes:TVadverts) %>%
  ggplot(aes(x = Month, y = value)) +
  geom_line() +
  facet_grid(vars(name), scales = "free_y") +
  labs(y = "", title = "Publicidad en seguros y cotizaciones")
```

Si parece que las dos series se mueven juntas, es decir, cuando se aumenta la publicidad parece haber un incremento en las cotizaciones.

Vamos a considerar 4 diferentes modelos, cada uno incluyendo un retardo de la publicidad desde el modelo de efecto instantáneo, hasta un modelo que considera hasta tres retardos de la inversión en publicidad. Por supuesto hay que cosiderar que todos los modelos trabajen sobre el mismo conjunto de entrenamiento. De nuevo el ajuste del modelo ARIMA es automático.

```{r Predictores retardados 2}
fit <- insurance %>%
  # Restrige los datos tal que los mkodelos usan el mismo periodo para el ajuste.
  mutate(Quotes = c(NA, NA, NA, Quotes[4:40])) %>%
  # Estimate models
  model(
    lag0 = ARIMA(Quotes ~ pdq(d = 0) + TVadverts),
    lag1 = ARIMA(Quotes ~ pdq(d = 0) +
                 TVadverts + lag(TVadverts)),
    lag2 = ARIMA(Quotes ~ pdq(d = 0) +
                 TVadverts + lag(TVadverts) +
                 lag(TVadverts, 2)),
    lag3 = ARIMA(Quotes ~ pdq(d = 0) +
                 TVadverts + lag(TVadverts) +
                 lag(TVadverts, 2) + lag(TVadverts, 3))
  )
```


```{r Predictores retardados 3}
glance(fit)
```

Basados en el criterio de AICc, podemos ver que el modelo lag1 es que minimiza este criterio, por lo tanto, ese será el que utilizaremos para la estimación incluyendo ahora si todas las observaciones.

```{r Predictores retardados 4}
fit_best <- insurance %>%
  model(ARIMA(Quotes ~ pdq(d = 0) +
              TVadverts + lag(TVadverts)))
report(fit_best)
coef(fit_best)
```
Note que para este modelo, todos los parámetros son significativos y el modelo para los errores es $ARIMA(1,0,2)$, o $ARMA(1,2)$, así el modelo final es
$$y_t=2.1554+1.2527x_t+0.1464x_{t-1}+\eta_t$$
$$\eta_t-0.5123\eta_{t-1}=\epsilon_t+0.9169\epsilon_{t-1}+0.4591\epsilon_{t-2}$$
Tarea: Evalúe los residuales del modelo y haga un reajuste de ser necesario.

Ahora produzcamos lo pronósticos para los siguientes 20 meses asuminedo un valor fijo de la publicidad en 8.

```{r Predictores retardados 5}
insurance_future <- new_data(insurance, 20) %>%
  mutate(TVadverts = 8)
fit_best %>%
  forecast(insurance_future) %>%
  autoplot(insurance) +
  labs(
    y = "Quotes",
    title = "Forecast quotes with future advertising set to 8"
  )

```


En seguida se visualizan los intervalos de pronóstico.

```{r intervalos de predicción}
fit_best %>%
  forecast(insurance_future)%>% hilo()
```

  
Tarea: Explore el conjunto de datos walmart_sales_weekly del paquete timetk, que son ventas semanales para una tienda Walmart, cuya descripción está en https://business-science.github.io/timetk/reference/walmart_sales_weekly.html. Estos datos son de una competencia en Kaggle(https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting/data), donde se espera proyectar las ventas de cada departamento(7 en total) usando las variables predictoras disponibles. Proponga dos modelos de los vistos en clase hasta para proyectar las venta de un departamento y evalué los pronósticos obtenidos(Entrenamineto 80%). No debe haber estudiantes con departamentos iguales. Tenga en cuenta que hay unos markdown solo se midieron desde el 2011 y por eso tiene NA's. 

```{r}
timetk::walmart_sales_weekly
```


```{r Gráfica serie un departamento}
dep=1
walmart_sales_weekly%>%group_by(Dept)%>%plot_time_series(Date,Weekly_Sales,.facet_ncol  = 2,    
                     .interactive = FALSE,.smooth=F)

```

  









